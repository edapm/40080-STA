# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value") +
theme_minimal()
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value") +
theme_minimal()
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value") +
theme_minimal()
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, shape = group)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value") +
theme_minimal()
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value") +
theme_minimal()
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
ggplot(aes(x = grain.diameter, y = average)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5, average), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot line of best fit for all groups combined
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = group)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
ggplot(dataset1, aes(x = grain.diameter, y = average)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group 1",
x = "Grain Diameter",
y = "Average")
ggplot(dataset1, aes(x = grain.diameter, y = average)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter Average",
x = "Grain Diameter",
y = "Average")
ggplot(dataset1, aes(x = grain.diameter, y = average, color = classification)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter Average",
x = "Grain Diameter",
y = "Average")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = classification)) +
geom_point() +
geom_smooth(method = "lm", se = F) +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
# plot x = grain.diameter, y = group.1, group.2, group.3, group.4, group.5 on ONE graph
dataset1 %>%
pivot_longer(cols = c(group.1, group.2, group.3, group.4, group.5), names_to = "group", values_to = "value") %>%
ggplot(aes(x = grain.diameter, y = value, color = classification)) +
geom_point() +
labs(title = "Grain Diameter vs Group",
x = "Grain Diameter",
y = "Value")
install.packages("Matrix")
dataset1<-read.csv(file.choose(), header = T, sep = ",")
density<-array[2.65, 2.23,2.23,2.65]
density<-array[2.65,2.23,2.23,2.65]
density<-c(2.65,2.23,2.23,2.65)
d_star1<-dataset1$grain.diameter[0]*(980.655(density[0] - 0.9982))^1/3
d_star1<-dataset1$grain.diameter[0]*(980.655*(density[0] - 0.9982))^1/3
d_star2<-dataset1$grain.diameter[1]*(980.655*(density[1] - 0.9982))^1/3
d_star1<-dataset1$grain.diameter[1]*(980.655*(density[0] - 0.9982))^1/3
d_star1<-dataset1$grain.diameter[1]*(980.655*(density[1] - 0.9982))^1/3
d_star2<-dataset1$grain.diameter[2]*(980.655*(density[2] - 0.9982))^1/3
d_star3<-dataset1$grain.diameter[3]*(980.655*(density[3] - 0.9982))^1/3
d_star4<-dataset1$grain.diameter[4]*(980.655*(density[4] - 0.9982))^1/3
print(dataset1$grain.diameter[1])
print(density[1])
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101)^1/3
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^1/3
dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^1/3
density[1] - 0.9982
980.655*(density[1] - 0.9982)
(980.655*(density[1] - 0.9982))/0.0101^2
(980.655*(density[1] - 0.9982)) / (0.0101)^2
0.6*(980.655*(density[1] - 0.9982)) / (0.0101)^2
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^1/3
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^1/3
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^1/3
0.6*((980.655*(density[1] - 0.9982)) / (0.0101)^2)^(1/3)
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^(1/3)
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^(1/3)
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^(1/3)
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^(1/3)
dataset1<-read.csv(file.choose(), header = T, sep = ",")
View(dataset1)
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^(1/3)
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^(1/3)
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^(1/3)
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^(1/3)
# calc d_star for each sample (for i in density)
d_star<-array[d_star1, d_star2, d_star3, d_star4]
# calc d_star for each sample (for i in density)
d_star<-c(d_star1, d_star2, d_star3, d_star4)
# calculate critical shear stress of each sample
dataset1$tau_c <- tau_star*(density-0.9982)*980.655*dataset1$grain.diameter
tau_star<-c(0.047, 0.054, 0.066, 0.101)
# calculate critical shear stress of each sample
dataset1$tau_c <- tau_star*(density-0.9982)*980.655*dataset1$grain.diameter
View(dataset1)
# plot tau_c against average
ggplot(dataset1, aes(x=grain.diameter, y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs grain diameter", x = "Grain diameter (mm)", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average, y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average[2,3], y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1[2,3], aes(x=average, y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
glass_beads<-c(dataset1[2],dataset1[3])
View(glass_beads)
# plot tau_c against average
ggplot(glass_beads, aes(x=average, y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
glass_beads<-(dataset1[2],dataset1[3])
glass_beads<-dataset1[2,3]
glass_beads<-filter(dataset1, classification == "glass beads")
View(glass_beads)
# plot tau_c against average
ggplot(glass_beads, aes(x=average, y=tau_c)) + geom_point() + geom_smooth(method = "lm", se = F) + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(glass_beads, aes(x=average, y=tau_c)) + geom_point() + geom_path() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
not_glass_beads<-filter(dataset1, classification != "glass beads")
ggplot(not_glass_beads, aes(x=average, y=tau_c)) + geom_point() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average, y=tau_c)) + geom_point() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification)) + geom_point() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification)) + geom_point() + geom_line(classification == "glass beads") + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
install.packages(c("cluster", "nloptr", "parsnip", "units"))
gc()
gc()
gc()
r.getVersion()
r version()
r getRversion()
getRversion()
gc()
library(tidyverse)
dataset1<-read.csv(file.choose(), header = T, sep = ",")
density<-c(2.65,2.23,2.23,2.65)
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^(1/3)
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^(1/3)
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^(1/3)
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^(1/3)
# calc d_star for each sample (for i in density)
d_star<-c(d_star1, d_star2, d_star3, d_star4)
# use d_star to find tau_star value using Shears Curve
tau_star<-c(0.047, 0.054, 0.066, 0.101)
# calculate critical shear stress of each sample
dataset1$tau_c <- tau_star*(density-0.9982)*980.655*dataset1$grain.diameter
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
rm(list=ls())
getCRANmirrors()
exit
exit()
q()
library(tidyverse)
dataset1<-read.csv(file.choose(), header = T, sep = ",")
density<-c(2.65,2.23,2.23,2.65)
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^(1/3)
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^(1/3)
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^(1/3)
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^(1/3)
# calc d_star for each sample (for i in density)
d_star<-c(d_star1, d_star2, d_star3, d_star4)
# use d_star to find tau_star value using Shears Curve
tau_star<-c(0.047, 0.054, 0.066, 0.101)
# calculate critical shear stress of each sample
dataset1$tau_c <- tau_star*(density-0.9982)*980.655*dataset1$grain.diameter
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
library(tidyverse)
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Pa)")
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress (Tc)")
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress")
library(tidyverse)
dataset1<-read.csv(file.choose(), header = T, sep = ",")
density<-c(2.65,2.23,2.23,2.65)
d_star1<-dataset1$grain.diameter[1]*((980.655*(density[1] - 0.9982))/0.0101^2)^(1/3)
d_star2<-dataset1$grain.diameter[2]*((980.655*(density[2] - 0.9982))/0.0101^2)^(1/3)
d_star3<-dataset1$grain.diameter[3]*((980.655*(density[3] - 0.9982))/0.0101^2)^(1/3)
d_star4<-dataset1$grain.diameter[4]*((980.655*(density[4] - 0.9982))/0.0101^2)^(1/3)
# calc d_star for each sample (for i in density)
d_star<-c(d_star1, d_star2, d_star3, d_star4)
# use d_star to find tau_star value using Shears Curve
tau_star<-c(0.031, 0.031, 0.035, 0.051)
# calculate critical shear stress of each sample
dataset1$tau_c <- tau_star*(density-0.9982)*980.655*dataset1$grain.diameter
# plot tau_c against average stirrer setting
ggplot(dataset1, aes(x=average, y=tau_c, shape=classification, group=classification)) + geom_point() + geom_line() + labs(title = "Critical shear stress vs stirrer setting", x = "Stirrer setting", y = "Critical shear stress")
rm(list=ls())
rm(list=ls())
knit_with_parameters("~/Documents/University/Geography Degree/Year 1/Semester 2/40080 LC Statistics (STA)/Code/Lecture Notes.Rmd")
help.start()
help()
citation()
contributors()
gc()
gc()
install.packages(c("commonmark", "doFuture", "duckdb", "Hmisc", "knitr", "mime", "nloptr", "Rdpack", "recipes", "sparsevctrs", "tzdb", "writexl", "xml2"))
dat <- read.csv(file.choose())
head(dat)
str(dat)
mod1 <- lm(death_rate ~ doctor + hospital + income + popn + random, data = dat)
View(mod1)
mod2 <- lm(death_rate ~ ., data = dat)
summary(mod1)
rm(list=(mod2))
rm(list=ls(mod2))
summary(mod1)
s <- summary(mod1)
s #both are reported on the penultimate row
s$r.squared
s$adj.r.squared
View(s)
dat$party <- sample(LETTERS[1:3], nrow(dat), replace = TRUE)
View(dat)
head(dat)
mod4 <- lm(death_rate ~ doctor + hospital + income +
popn + random + party,
data = dat)
summary(mod4)
anova(mod4)
drop1(mod1, "doctor")
step(mod1, direction = "both") # direction = both means it does stepwise (rather than backwards selection etc)
x <- step(mod1, direction = "both", trace = FALSE) # trace = FALSE stops it printing the full process
x
summary(x) #we can access this like a normal regression model object
x
new_dat <- data.frame("doctor" = c(7, 3), "income" = c(8, 2))
new_dat
predict(x, newdata = new_dat)
summary(x)
predict(x, newdata = new_dat)
summary(x)
#get the model coefficients
x$coefficients
17.9479702 + (-0.7991483 * 7) + (-0.4280801 * 8)
#match this with the predict function (we only predicted the first value here remember)
predict(x, newdata = new_dat)
rm(list=ls())
dat <- read.csv(file.choose())
head(dat)
l <- lm(data = dat, Crime_rate ~ .)
View(l)
l <- lm(data = dat, Crime_rate ~ .)
sum_l <- summary(l)
model_r2 <- sum_l$r.squared
model_adjr2 <- sum_l$adj.r.squared
sum_;
sum_l
aov(l)
x <- step(l, direction = "both")
summary(x)
# Use the drop1 function to test dropping the Youth variable from this
# simplified model. What happens to the model AIC? Then use add1() to add back
# in the Males variables. Based on this, is our model selection correct in
# including Youth in the optimal model and excluding Males?
# Remember: a lower AIC means a better fitting model, and the model with the
# added/removed variable is on the second row.
drop1(l, "Youth")
add1(l, "Males")
summary(l)
# Use the drop1 function to test dropping the Youth variable from this
# simplified model. What happens to the model AIC? Then use add1() to add back
# in the Males variables. Based on this, is our model selection correct in
# including Youth in the optimal model and excluding Males?
# Remember: a lower AIC means a better fitting model, and the model with the
# added/removed variable is on the second row.
drop1(x, "Youth")
add1(x, "Males")
summary(x)
# Use the drop1 function to test dropping the Youth variable from this
# simplified model. What happens to the model AIC? Then use add1() to add back
# in the Males variables. Based on this, is our model selection correct in
# including Youth in the optimal model and excluding Males?
# Remember: a lower AIC means a better fitting model, and the model with the
# added/removed variable is on the second row.
y <- drop1(x, "Youth")
z <- add1(y, "Males")
# Use the drop1 function to test dropping the Youth variable from this
# simplified model. What happens to the model AIC? Then use add1() to add back
# in the Males variables. Based on this, is our model selection correct in
# including Youth in the optimal model and excluding Males?
# Remember: a lower AIC means a better fitting model, and the model with the
# added/removed variable is on the second row.
drop1(x, "Youth")
add1(x, "Males")
# have a go at building a MLR model, with crime rate as the response variable
# and with two predictors: ExpenditureYear0 and StateSize. And then also testing
# the interaction between them. Look at the summary of the this model and the
# coefficient and significance of the interaction term. Was our hypothesis of an
# interaction correct?
y <- lm(data = dat, Crime_rate ~ ExpenditureYear0 * StateSize)
summary(y)
rm(list=ls())
demo()
grDevices.colors()
library(grDevices)
grDevices.colors()
library(base)
error.catching()
install.packages("datarium")
library(datarium)
data(marketing)
head(marketing)
View(marketing)
mod <- lm(sales ~ youtube, data = marketing)
summary(mod)
#Plot the model fit
plot(marketing$youtube, marketing$sales)
lines(marketing$youtube, fitted(mod))
install.packages("broom")
#install.packages("broom")
library(broom)
model.res <- augment(mod)
head(model.res) #ignore the other columns for now
par(mfrow = c(2, 2))
plot(mod)
dev.off()#first run this to turn off the 4 plots, so the new plots can fill up the whole plotting window (rather than 1/4)
plot(mod, 2)
r <- residuals(mod)
hist(r)
shapiro.test(r)
plot(mod, 1)
install.packages(c("airGRteaching", "clock", "curl", "foreign", "geodist", "gert", "httr2", "hunspell", "jsonlite", "lme4", "markdown", "MatrixModels", "parallelly", "pkgbuild", "psych", "recipes", "reticulate", "sf", "sparsevctrs", "stringi"))
plot(mod, 1)
plot(mod, 3)
#To try the first option (log-transforming the response variable):
mod2 <- lm(log(sales) ~ youtube, data = marketing)
plot(mod2, 3)#we then re-make the plot to see if it has helped - has it?
plot(mod, 4)
plot(mod, 5)
cor(marketing)
plot(marketing)
mod2 <- lm(sales ~., data = marketing)
summary(mod2)
library(olsrr)
ols_vif_tol(mod2)
# Load it in and call it 'dat'. Have a look at it using the head() function.
dat <- read.csv(file.choose(), header = TRUE)
rm(list=ls())
# Load it in and call it 'dat'. Have a look at it using the head() function.
dat <- read.csv(file.choose(), header = TRUE)
# First, fit a simple linear model (call it mod) using heart.disease as your
# response variable and biking as your single predictor variable. And then look
# at the summary and plot the fit of the model using code learnt in previous
# practicals
mod <- lm(heart.disease ~ biking, data = dat)
summary(mod)
plot(mod)
plot(heart.disease ~ biking, data = dat)
lines(dat$biking, fitted(mod), col = "red")
## Testing assumptions
# Now, using this model test the assumptions of linear regression you went over
# in the main practical. First, check the normality of the residuals assumption
# by looking at the QQ plot and by running a Shapiro Wilks test.
plot(mod, 1)
shapiro.test(resid(mod))
## Testing assumptions
# Now, using this model test the assumptions of linear regression you went over
# in the main practical. First, check the normality of the residuals assumption
# by looking at the QQ plot and by running a Shapiro Wilks test.
plot(mod, 2)
mod2 <- lm(log(heart.disease) ~ biking, data = dat)
install.packages(c("airGRteaching", "stringi"))
plot(mod2, 2)
shapiro.test(resid(mod2))
c
cor.test(dat$biking, dat$smoking) #QUESTION: how does this look?
mod3 <- lm(heart.disease ~ biking + smoking, data = dat)
plot(mod3, 2)
shapiro.test(resid(mod3))
# Now examine the linearity assumption and the homogeneity of (residual)
# variance assumption using the relevant plots we went over in the practical,
# using this new 'mod3'.
plot(mod3, 1)
# using mod3, look at the relevant plots for checking for influential outliers.
# Do you think there is any problems with outliers in our model? Remember to
# look at the Cook's distance values and the standardised residuals values.
plot(mod3, 3)
# using mod3, look at the relevant plots for checking for influential outliers.
# Do you think there is any problems with outliers in our model? Remember to
# look at the Cook's distance values and the standardised residuals values.
plot(mod3, 4)
dat2 <- rbind(dat, c(4, 1, 100))
mod3 <- lm(heart.disease ~ biking + smoking, data = dat2)
# Look at the Cook's distance and standardized residual of this new point. You
# can now see what a true influential outlier looks like!
plot(mod3, 4)
install.packages("DHARMa")
#install.packages("DHARMa")
library(DHARMa)
#just run this as is to simulate the data and call it testData
testData <- createData(sampleSize = 100, family = gaussian(),
temporalAutocorrelation = 5)
#just run this as is to simulate the data and call it testData
testData <- createData(sampleSize = 100, family = gaussian(),
temporalAutocorrelation = 5)
install.packages(sfsmisc)
install.packages("sfsmisc")
library(sfsmisc)
#just run this as is to simulate the data and call it testData
testData <- createData(sampleSize = 100, family = gaussian(),
temporalAutocorrelation = 5)
#now we fit a lm model with observedResponse as the response variable,
#and Environment1 as the predictor, in the testData dataset
testMod <- lm(observedResponse ~ Environment1, data = testData)
#Now run the durbin watson test on this model's residuals (remember, we just give the
#function the model, it extracts the residuals itself)
library(car)
durbinWatsonTest(testMod)
rm(list=ls())
setwd("~/Documents/University/Geography Degree/Year 1/Semester 2/40080 LC Statistics (STA)/Code/Assessment")
library(tidyverse)
data <- read.csv("data.csv", header=T, sep=",")
View(data)
View(data)
mod <- lm(rainfall~., data = data)
View(mod)
mod_step <- step(mod, direction = "both")
summary(mod_step)
plot(mod_step)
